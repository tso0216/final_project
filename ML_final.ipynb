{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess"
      ],
      "metadata": {
        "id": "ihLtSOzbRpa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "9EKLLIcX0zBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\n",
        "    \"brendanartley/cartoon-faces-googles-cartoon-set\"\n",
        ")\n",
        "dataset_path = path + '/cartoonset100k_jpg/'\n",
        "\n",
        "IMG_HEIGHT = 96\n",
        "IMG_WIDTH = 96\n",
        "BATCH_SIZE = 64\n",
        "LATENT_DIM = 128\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    label_mode=None,\n",
        "    color_mode='rgb',\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),  #resize\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "n-Fq73IQ1uxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build\n"
      ],
      "metadata": {
        "id": "uTBmxNOFP_Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# 取樣層\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "encoder_inputs = layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "#Encoder\n",
        "x = layers.Conv2D(64, 3, strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2D(256, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2D(512, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "shape_before_flatten = K.int_shape(x)[1:]\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "\n",
        "z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(LATENT_DIM, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "\n",
        "#Decoder\n",
        "latent_inputs = layers.Input(shape=(LATENT_DIM,))\n",
        "\n",
        "x = layers.Dense(shape_before_flatten[0] * shape_before_flatten[1] * shape_before_flatten[2], activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape(shape_before_flatten)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(512, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(256, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(128, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
      ],
      "metadata": {
        "id": "rAVo3xupQA6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction\n",
        "\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "\n",
        "            #重建loss\n",
        "            reconstruction_loss = tf.reduce_sum(\n",
        "              tf.keras.losses.binary_crossentropy(data, reconstruction),\n",
        "              axis=(1, 2)\n",
        "            )\n",
        "            #KL loss\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
        "\n",
        "            beta = 0.5\n",
        "            total_loss = tf.reduce_mean(reconstruction_loss + beta * kl_loss)\n",
        "\n",
        "\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "ppLJhRi8QGB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#training"
      ],
      "metadata": {
        "id": "71PFba2LPmf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))"
      ],
      "metadata": {
        "id": "WKFa1zXN6AhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vae.build((BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "# vae.load_weights('vae_cartoon_faces_v3.keras')"
      ],
      "metadata": {
        "id": "YrzFzc9EsT-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = vae.fit(train_ds, epochs=10)"
      ],
      "metadata": {
        "id": "u2OlDK-S6FJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vae.save('vae_cartoon_faces_v5.keras')"
      ],
      "metadata": {
        "id": "aX1NE1t2RVJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# result\n"
      ],
      "metadata": {
        "id": "z6qB6kvcSOm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_results(vae, data, n=8):\n",
        "\n",
        "    images = next(iter(data))[:n]\n",
        "    encoded_imgs = vae.encoder(images)\n",
        "    z_mean, z_log_var, z = encoded_imgs\n",
        "    decoded_imgs = vae.decoder(z)\n",
        "\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    for i in range(n):\n",
        "        # 原圖\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "        plt.title(\"Original\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # 重建圖\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_imgs[i].numpy())\n",
        "        plt.title(\"Reconstructed\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    # 生成測試\n",
        "    random_latent_vectors = tf.random.normal(shape=(n, LATENT_DIM))\n",
        "    generated_images = vae.decoder(random_latent_vectors)\n",
        "\n",
        "    plt.figure(figsize=(20, 3))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(1, n, i + 1)\n",
        "        plt.title(\"Random Generate\")\n",
        "        plt.imshow(generated_images[i].numpy())\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_results(vae, train_ds)"
      ],
      "metadata": {
        "id": "EK9SDYRs6SS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "reconstruction_loss = history.history['reconstruction_loss']\n",
        "kl_loss = history.history['kl_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs, loss, label='Total Loss')\n",
        "plt.title('Total Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, reconstruction_loss, label='Reconstruction Loss', color='orange')\n",
        "plt.title('Reconstruction Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(epochs, kl_loss, label='KL Loss', color='green')\n",
        "plt.title('KL Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l-WfgOFsLnSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# result - reconstruction\n"
      ],
      "metadata": {
        "id": "PpaQE_JKkler"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstruction(vae, data, n=8):\n",
        "\n",
        "    images = next(iter(data))[:n]\n",
        "\n",
        "    encoded_imgs = vae.encoder(images)\n",
        "    z_mean, z_log_var, z = encoded_imgs\n",
        "    decoded_imgs = vae.decoder(z)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(n):\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(images[i].numpy())\n",
        "        plt.title(\"Original\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_imgs[i].numpy())\n",
        "        plt.title(\"Reconstructed\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Reconstruction Check (Input vs Output)\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "def plot_interpolation(vae, data, steps=10):\n",
        "\n",
        "    images = next(iter(data))[:2]\n",
        "    image_a = images[0:1]\n",
        "    image_b = images[1:2]\n",
        "\n",
        "    z_a, _, _ = vae.encoder(image_a)\n",
        "    z_b, _, _ = vae.encoder(image_b)\n",
        "\n",
        "\n",
        "    alphas = np.linspace(0, 1, steps)\n",
        "    z_interpolated = np.array([z_a * (1 - alpha) + z_b * alpha for alpha in alphas])\n",
        "    z_interpolated = z_interpolated.reshape(steps, -1)\n",
        "\n",
        "    decoded_imgs = vae.decoder(z_interpolated)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(20, 3))\n",
        "    for i in range(steps):\n",
        "        ax = plt.subplot(1, steps, i + 1)\n",
        "        plt.imshow(decoded_imgs[i].numpy())\n",
        "        plt.axis(\"off\")\n",
        "        if i == 0:\n",
        "            plt.title(\"Start (A)\")\n",
        "        elif i == steps - 1:\n",
        "            plt.title(\"End (B)\")\n",
        "\n",
        "    plt.suptitle(\"Latent Space Interpolation\", fontsize=16)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "qxX5G9uIi0Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_reconstruction(vae, train_ds)"
      ],
      "metadata": {
        "id": "hJw4PaR6kvGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_interpolation(vae, train_ds)"
      ],
      "metadata": {
        "id": "7Rz_ybzCLnX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# result - latent generate"
      ],
      "metadata": {
        "id": "6ndjD0qukwDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def generate_with_latent_analysis(vae, n=5, latent_dim=128):\n",
        "\n",
        "    z = tf.random.normal(shape=(n, latent_dim))\n",
        "    generated_images = vae.decoder(z)\n",
        "    plt.figure(figsize=(20, 6))\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(generated_images[i].numpy())\n",
        "        plt.title(f\"Image {i+1}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        vector_visualization = z[i].numpy().reshape(1, -1)\n",
        "\n",
        "        plt.imshow(vector_visualization, aspect='auto', cmap='viridis')\n",
        "        plt.title(f\"Latent Vector {i+1}\")\n",
        "\n",
        "        plt.yticks([])\n",
        "        plt.xlabel(\"Dim: 0 ~ 127\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return z.numpy()\n",
        "\n",
        "latent_vectors = generate_with_latent_analysis(vae, n=5, latent_dim=LATENT_DIM)"
      ],
      "metadata": {
        "id": "OwEs_0UnjM0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_cumulative_curve(vae, data, n_samples=3000):\n",
        "\n",
        "    images = []\n",
        "    for batch in data:\n",
        "        images.append(batch)\n",
        "        if len(images) * batch.shape[0] >= n_samples:\n",
        "            break\n",
        "    x_test = np.concatenate(images, axis=0)[:n_samples]\n",
        "    z_mean, _, _ = vae.encoder.predict(x_test, verbose=0)\n",
        "\n",
        "    pca = PCA()\n",
        "    pca.fit(z_mean)\n",
        "\n",
        "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, linewidth=2)\n",
        "\n",
        "    plt.title(\"PCA Cumulative Variance\")\n",
        "    plt.xlabel(\"Number of PCs\")\n",
        "    plt.ylabel(\"Explained Variance (0.0 ~ 1.0)\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.ylim(0, 1.05)\n",
        "\n",
        "    print(f\"前 15 個 PC 累積了解釋度: {cumulative_variance[14]:.2%}\")\n",
        "\n",
        "    return pca, z_mean\n",
        "\n",
        "def analyze_pca_2d(vae, pca, z_mean, grid_size=15):\n",
        "\n",
        "    ratios = pca.explained_variance_ratio_\n",
        "\n",
        "    print(f\"PC 1 解釋變異量: {ratios[0]:.2%}\")\n",
        "    print(f\"PC 2 解釋變異量: {ratios[1]:.2%}\")\n",
        "    print(f\"兩者合計 (PC1 + PC2): {ratios[0] + ratios[1]:.2%}\")\n",
        "\n",
        "    scale = 2.0\n",
        "\n",
        "    grid_x = np.linspace(-scale, scale, grid_size)\n",
        "    grid_y = np.linspace(-scale, scale, grid_size)\n",
        "\n",
        "    z_center = np.mean(z_mean, axis=0)\n",
        "    pc1_vec = pca.components_[0]\n",
        "    pc2_vec = pca.components_[1]\n",
        "    std_devs = np.sqrt(pca.explained_variance_)\n",
        "\n",
        "    img_h, img_w = 96, 96\n",
        "    figure = np.zeros((img_h * grid_size, img_w * grid_size, 3))\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "\n",
        "            z_sample = z_center + (xi * std_devs[0] * pc1_vec) + (yi * std_devs[1] * pc2_vec)\n",
        "            z_sample = np.expand_dims(z_sample, axis=0)\n",
        "            x_decoded = vae.decoder.predict(z_sample, verbose=0)\n",
        "            digit = x_decoded[0].reshape(img_h, img_w, 3)\n",
        "            figure[i * img_h : (i + 1) * img_h,j * img_w : (j + 1) * img_w] = digit\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.imshow(figure)\n",
        "    plt.title(\"2D Face Map (PC1 vs PC2)\", fontsize=20)\n",
        "    plt.xlabel(f\"PC 1 (Variance: {ratios[0]:.2%}) \")\n",
        "    plt.ylabel(f\"PC 2 (Variance: {ratios[1]:.2%}) \")\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n"
      ],
      "metadata": {
        "id": "XFjJRkn1IwOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_full, z_mean_data = plot_cumulative_curve(vae, train_ds)"
      ],
      "metadata": {
        "id": "aFVmgbdNK547"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_pca_2d(vae, pca_full, z_mean_data)"
      ],
      "metadata": {
        "id": "HQ-BuMgxK7hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_pca(vae, pca, z_mean, n_components=8):\n",
        "\n",
        "    z_center = np.mean(z_mean, axis=0)\n",
        "    std_devs = np.sqrt(pca.explained_variance_)[:n_components]\n",
        "    grid_steps = 13\n",
        "    factors = np.linspace(-3, 3, grid_steps)\n",
        "\n",
        "    plt.figure(figsize=(25, 2.5 * n_components))\n",
        "\n",
        "    for i in range(n_components):\n",
        "        component_vector = pca.components_[i]\n",
        "        std = std_devs[i]\n",
        "\n",
        "        z_line = []\n",
        "        for f in factors:\n",
        "            z_new = z_center + (f * std * component_vector)\n",
        "            z_line.append(z_new)\n",
        "\n",
        "        z_line = np.array(z_line)\n",
        "        decoded_imgs = vae.decoder(z_line)\n",
        "\n",
        "        for j in range(grid_steps):\n",
        "            ax = plt.subplot(n_components, grid_steps, i * grid_steps + j + 1)\n",
        "\n",
        "            plt.imshow(decoded_imgs[j].numpy())\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            if j == 0:\n",
        "                ax.set_title(f\"PC {i+1} (-)\", loc='left', fontsize=12)\n",
        "            if j == grid_steps // 2:\n",
        "                if i == 0: ax.set_title(\"Average\", fontsize=12)\n",
        "            if j == grid_steps - 1:\n",
        "                ax.set_title(f\"PC {i+1} (+)\", loc='right', fontsize=12)\n",
        "\n",
        "    plt.suptitle(f\"Top {n_components} Latent Factors of Variation (PCA) - {grid_steps} Steps\", fontsize=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "analyze_pca(vae, pca_full, z_mean_data, n_components=8)"
      ],
      "metadata": {
        "id": "rAB1NmNCn8ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
